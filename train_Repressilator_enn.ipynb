{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "75e1510848ff81b2a8a3022c3bfac472ed28a49a56e1422a056d525171f2408b"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPjTnCG-v2Z6",
        "outputId": "60c83234-aef7-4963-e42a-93228b4d0421"
      },
      "source": [
        "\"\"\"\n",
        "Notebook for training the embedding model for the Rossler system.\n",
        "Since this is not a built in example, we will need to implement our our config,\n",
        "model and data handler.\n",
        "=====\n",
        "Distributed by: Notre Dame SCAI Lab (MIT Liscense)\n",
        "- Associated publication:\n",
        "url: https://arxiv.org/abs/2010.03957\n",
        "doi:\n",
        "github: https://github.com/zabaras/transformer-physx\n",
        "=====\n",
        "\"\"\"\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34XMtg9FZFql"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuqsYQ_2S4kq"
      },
      "source": [
        "Use pip to install from [PyPI](https://pypi.org/project/trphysx/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvm518_H3AK7",
        "outputId": "c4f8ea0b-2bd3-4f98-8e3e-8e5c94431b67"
      },
      "source": [
        "!pip install trphysx==0.0.7"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trphysx==0.0.7\n",
            "  Downloading trphysx-0.0.7-py3-none-any.whl (137 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m133.1/137.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from trphysx==0.0.7) (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from trphysx==0.0.7) (3.14.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from trphysx==0.0.7) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from trphysx==0.0.7) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from trphysx==0.0.7) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->trphysx==0.0.7) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->trphysx==0.0.7) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->trphysx==0.0.7) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->trphysx==0.0.7) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->trphysx==0.0.7) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->trphysx==0.0.7) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7.0->trphysx==0.0.7)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7.0->trphysx==0.0.7)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7.0->trphysx==0.0.7)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7.0->trphysx==0.0.7)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7.0->trphysx==0.0.7)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7.0->trphysx==0.0.7)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7.0->trphysx==0.0.7)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7.0->trphysx==0.0.7)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7.0->trphysx==0.0.7)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.7.0->trphysx==0.0.7)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7.0->trphysx==0.0.7)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->trphysx==0.0.7) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->trphysx==0.0.7)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->trphysx==0.0.7) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->trphysx==0.0.7) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->trphysx==0.0.7) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, trphysx\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 trphysx-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoBoGx0J0LtZ"
      },
      "source": [
        "Mount google drive and create a folder to work in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K0hSst0b2Ak",
        "outputId": "e02f402d-0926-43f7-9d52-193d49fd3bf0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zaXL-m8xEx9",
        "outputId": "f194e654-b399-4aca-afdc-4404a7fbd8ac"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/\n",
        "%mkdir -p transformer_physx/Repressilator\n",
        "%cd transformer_physx/Repressilator"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n",
            "/content/gdrive/MyDrive/transformer_physx/Repressilator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MK_h8wF0Rr4"
      },
      "source": [
        "Now lets download the training and validation data for the lorenz system. Info on wget from [Google drive](https://stackoverflow.com/questions/37453841/download-a-file-from-google-drive-using-wget). This will eventually be update to zenodo repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NtZ02zD0EKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08fa5d74-e116-4618-e55a-82477a7943ee"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU702uo6xIQQ",
        "outputId": "af80846d-f952-4dd3-ae4d-3f81b7623819"
      },
      "source": [
        "# Updated it with the links from your google drive where generated data is residing\n",
        "#!wget -O ./data/Repressilator_training.hdf5 \"https://drive.google.com/file/d/1zJgNPF2jVnIBy0zod6XnFGKj4OHdGs9t/view?usp=sharing\"\n",
        "#!wget -O ./data/Repressilator_valid.hdf5 \"https://drive.google.com/file/d/1wGGAf077MbZ7gBdz0s3RI5nZIY-fSCVt/view?usp=sharing\"\n",
        "# from the share link only copy the id of the file and add it to the link below\n",
        "!wget 'https://docs.google.com/uc?export=download&id=1zJgNPF2jVnIBy0zod6XnFGKj4OHdGs9t' -O ./data/Repressilator_training_1.hdf5\n",
        "!wget 'https://docs.google.com/uc?export=download&id=1wGGAf077MbZ7gBdz0s3RI5nZIY-fSCVt' -O ./data/Repressilator_valid_1.hdf5"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-12 10:24:10--  https://docs.google.com/uc?export=download&id=1zJgNPF2jVnIBy0zod6XnFGKj4OHdGs9t\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.2.113, 142.251.2.139, 142.251.2.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.2.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1zJgNPF2jVnIBy0zod6XnFGKj4OHdGs9t&export=download [following]\n",
            "--2024-06-12 10:24:10--  https://drive.usercontent.google.com/download?id=1zJgNPF2jVnIBy0zod6XnFGKj4OHdGs9t&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.2.132, 2607:f8b0:4023:c0b::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6396672 (6.1M) [application/octet-stream]\n",
            "Saving to: ‘./data/Repressilator_training_1.hdf5’\n",
            "\n",
            "./data/Repressilato 100%[===================>]   6.10M  25.2MB/s    in 0.2s    \n",
            "\n",
            "2024-06-12 10:24:13 (25.2 MB/s) - ‘./data/Repressilator_training_1.hdf5’ saved [6396672/6396672]\n",
            "\n",
            "--2024-06-12 10:24:13--  https://docs.google.com/uc?export=download&id=1wGGAf077MbZ7gBdz0s3RI5nZIY-fSCVt\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.2.113, 142.251.2.139, 142.251.2.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.2.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1wGGAf077MbZ7gBdz0s3RI5nZIY-fSCVt&export=download [following]\n",
            "--2024-06-12 10:24:13--  https://drive.usercontent.google.com/download?id=1wGGAf077MbZ7gBdz0s3RI5nZIY-fSCVt&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.2.132, 2607:f8b0:4023:c0b::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 801536 (783K) [application/octet-stream]\n",
            "Saving to: ‘./data/Repressilator_valid_1.hdf5’\n",
            "\n",
            "./data/Repressilato 100%[===================>] 782.75K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-06-12 10:24:13 (5.64 MB/s) - ‘./data/Repressilator_valid_1.hdf5’ saved [801536/801536]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCHiYnrdZN95"
      },
      "source": [
        "# Transformer-PhysX Repressilator System\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoNLzt1xuQk4"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import logging\n",
        "import h5py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from typing import Dict, List, Tuple\n",
        "# Torch imports\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "# Trphysx imports\n",
        "from trphysx.embedding import EmbeddingModel\n",
        "from trphysx.config.configuration_phys import PhysConfig\n",
        "from trphysx.embedding import EmbeddingTrainingHead\n",
        "from trphysx.embedding.training import EmbeddingParser, EmbeddingDataHandler, EmbeddingTrainer\n",
        "\n",
        "Tensor = torch.Tensor\n",
        "TensorTuple = Tuple[torch.Tensor]\n",
        "FloatTuple = Tuple[float]\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "argv = []\n",
        "argv = argv + [\"--exp_name\", \"rossler\"]\n",
        "argv = argv + [\"--training_h5_file\", \"./data/Repressilator_training.hdf5\"]\n",
        "argv = argv + [\"--eval_h5_file\", \"./data/Repressilator_valid.hdf5\"]\n",
        "argv = argv + [\"--stride\", \"16\"]\n",
        "argv = argv + [\"--batch_size\", \"256\"]\n",
        "argv = argv + [\"--block_size\", \"16\"]\n",
        "argv = argv + [\"--n_train\", \"1024\"]\n",
        "argv = argv + [\"--n_eval\", \"32\"]\n",
        "argv = argv + [\"--epochs\", \"300\"]\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    filename='logging.log',\n",
        "    filemode='a',\n",
        "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "    level=logging.DEBUG,\n",
        "    force=True,)\n",
        "\n",
        "args = EmbeddingParser().parse(argv)\n",
        "if(torch.cuda.is_available()):\n",
        "    use_cuda = \"cuda\"\n",
        "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger.info(\"Torch device: {}\".format(args.device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYzPn4lLtaNI"
      },
      "source": [
        "## Repressilator Config Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYHwOXUWtcny"
      },
      "source": [
        "class RepressilatorConfig(PhysConfig):\n",
        "    \"\"\"\n",
        "    This is the configuration class for the modeling of the Repressilator system.\n",
        "    \"\"\"\n",
        "    # same model as rossler\n",
        "    model_type = \"rossler\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_ctx=32,\n",
        "        n_embd=32,\n",
        "        n_layer=4,\n",
        "        n_head=4, # n_head must be a factor of n_embd\n",
        "        state_dims=[3],\n",
        "        activation_function=\"gelu_new\",\n",
        "        initializer_range=0.02,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            n_ctx=n_ctx,\n",
        "            n_embd=n_embd,\n",
        "            n_layer=n_layer,\n",
        "            n_head=n_head,\n",
        "            state_dims=state_dims,\n",
        "            activation_function=activation_function,\n",
        "            initializer_range=initializer_range,\n",
        "            **kwargs\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAefNqpuqaZa"
      },
      "source": [
        "## Embedding Neural Network Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CJq3y09rSIQ"
      },
      "source": [
        "class RepressilatorEmbedding(EmbeddingModel):\n",
        "    \"\"\"Embedding model for the Repressilator ODE system\n",
        "\n",
        "    Args:\n",
        "        config (PhysConfig) Configuration class with transformer/embedding parameters\n",
        "    \"\"\"\n",
        "    model_name = \"embedding_rossler\"\n",
        "\n",
        "    def __init__(self, config: PhysConfig) -> None:\n",
        "        \"\"\"Constructor method\n",
        "        \"\"\"\n",
        "        super().__init__(config)\n",
        "\n",
        "        hidden_states = int(abs(config.state_dims[0] - config.n_embd)/2) + 1\n",
        "        hidden_states = 500\n",
        "\n",
        "        self.observableNet = nn.Sequential(\n",
        "            nn.Linear(config.state_dims[0], hidden_states),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_states, config.n_embd),\n",
        "            nn.LayerNorm(config.n_embd, eps=config.layer_norm_epsilon),\n",
        "            nn.Dropout(config.embd_pdrop)\n",
        "        )\n",
        "\n",
        "        self.recoveryNet = nn.Sequential(\n",
        "            nn.Linear(config.n_embd, hidden_states),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_states, config.state_dims[0])\n",
        "        )\n",
        "        # Learned koopman operator\n",
        "        # Learns skew-symmetric matrix with a diagonal\n",
        "        self.obsdim = config.n_embd\n",
        "        self.kMatrixDiag = nn.Parameter(torch.linspace(1, 0, config.n_embd))\n",
        "\n",
        "        xidx = []\n",
        "        yidx = []\n",
        "        for i in range(1, 3):\n",
        "            yidx.append(np.arange(i, config.n_embd))\n",
        "            xidx.append(np.arange(0, config.n_embd-i))\n",
        "\n",
        "        self.xidx = torch.LongTensor(np.concatenate(xidx))\n",
        "        self.yidx = torch.LongTensor(np.concatenate(yidx))\n",
        "        self.kMatrixUT = nn.Parameter(0.1*torch.rand(self.xidx.size(0)))\n",
        "        # Normalization occurs inside the model\n",
        "        self.register_buffer('mu', torch.tensor([0., 0., 0.]))\n",
        "        self.register_buffer('std', torch.tensor([1., 1., 1.]))\n",
        "        print('Number of embedding parameters: {}'.format( super().num_parameters ))\n",
        "\n",
        "    def forward(self, x: Tensor) -> TensorTuple:\n",
        "        \"\"\"Forward pass\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): [B, 3] Input feature tensor\n",
        "\n",
        "        Returns:\n",
        "            (tuple): tuple containing:\n",
        "\n",
        "                | (torch.Tensor): [B, config.n_embd] Koopman observables\n",
        "                | (torch.Tensor): [B, 3] Recovered feature tensor\n",
        "        \"\"\"\n",
        "        # Encode\n",
        "        x = self._normalize(x)\n",
        "        g = self.observableNet(x)\n",
        "        # Decode\n",
        "        out = self.recoveryNet(g)\n",
        "        xhat = self._unnormalize(out)\n",
        "        return g, xhat\n",
        "\n",
        "    def embed(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Embeds tensor of state variables to Koopman observables\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): [B, 3] input feature tensor\n",
        "\n",
        "        Returns:\n",
        "            (Tensor): [B, config.n_embd] Koopman observables\n",
        "        \"\"\"\n",
        "        x = self._normalize(x)\n",
        "        g = self.observableNet(x)\n",
        "        return g\n",
        "\n",
        "    def recover(self, g: Tensor) -> Tensor:\n",
        "        \"\"\"Recovers feature tensor from Koopman observables\n",
        "\n",
        "        Args:\n",
        "            g (Tensor): [B, config.n_embd] Koopman observables\n",
        "\n",
        "        Returns:\n",
        "            (Tensor): [B, 3] Physical feature tensor\n",
        "        \"\"\"\n",
        "        out = self.recoveryNet(g)\n",
        "        x = self._unnormalize(out)\n",
        "        return x\n",
        "\n",
        "    def koopmanOperation(self, g: Tensor) -> Tensor:\n",
        "        \"\"\"Applies the learned koopman operator on the given observables.\n",
        "\n",
        "        Args:\n",
        "            (Tensor): [B, config.n_embd] Koopman observables\n",
        "\n",
        "        Returns:\n",
        "            (Tensor): [B, config.n_embd] Koopman observables at the next time-step\n",
        "        \"\"\"\n",
        "        # Koopman operator\n",
        "        kMatrix = Variable(torch.zeros(self.obsdim, self.obsdim)).to(self.kMatrixUT.device)\n",
        "        # Populate the off diagonal terms\n",
        "        kMatrix[self.xidx, self.yidx] = self.kMatrixUT\n",
        "        kMatrix[self.yidx, self.xidx] = -self.kMatrixUT\n",
        "\n",
        "        # Populate the diagonal\n",
        "        ind = np.diag_indices(kMatrix.shape[0])\n",
        "        kMatrix[ind[0], ind[1]] = self.kMatrixDiag\n",
        "\n",
        "        # Apply Koopman operation\n",
        "        gnext = torch.bmm(kMatrix.expand(g.size(0), kMatrix.size(0), kMatrix.size(0)), g.unsqueeze(-1))\n",
        "        self.kMatrix = kMatrix\n",
        "        return gnext.squeeze(-1) # Squeeze empty dim from bmm\n",
        "\n",
        "    @property\n",
        "    def koopmanOperator(self, requires_grad: bool = True) -> Tensor:\n",
        "        \"\"\"Current Koopman operator\n",
        "\n",
        "        Args:\n",
        "            requires_grad (bool, optional): if to return with gradient storage, defaults to True\n",
        "        \"\"\"\n",
        "        if not requires_grad:\n",
        "            return self.kMatrix.detach()\n",
        "        else:\n",
        "            return self.kMatrix\n",
        "\n",
        "    def _normalize(self, x: Tensor) -> Tensor:\n",
        "        return (x - self.mu.unsqueeze(0))/self.std.unsqueeze(0)\n",
        "\n",
        "    def _unnormalize(self, x: Tensor) -> Tensor:\n",
        "        return self.std.unsqueeze(0)*x + self.mu.unsqueeze(0)\n",
        "\n",
        "    @property\n",
        "    def koopmanDiag(self):\n",
        "        return self.kMatrixDiag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEUXXK7Tt-HG"
      },
      "source": [
        "## Embedding Network Trainer Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBUQygCfuC1P"
      },
      "source": [
        "class RepressilatorEmbeddingTrainer(EmbeddingTrainingHead):\n",
        "    \"\"\"Training head for the Repressilator embedding model for parallel training\n",
        "\n",
        "    Args:\n",
        "        config (PhysConfig) Configuration class with transformer/embedding parameters\n",
        "    \"\"\"\n",
        "    def __init__(self, config: PhysConfig) -> None:\n",
        "        \"\"\"Constructor method\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.embedding_model = RepressilatorEmbedding(config)\n",
        "\n",
        "    def forward(self, states: Tensor) -> FloatTuple:\n",
        "        \"\"\"Trains model for a single epoch\n",
        "\n",
        "        Args:\n",
        "            states (Tensor): [B, T, 3] Time-series feature tensor\n",
        "\n",
        "        Returns:\n",
        "            FloatTuple: Tuple containing:\n",
        "\n",
        "                | (float): Koopman based loss of current epoch\n",
        "                | (float): Reconstruction loss\n",
        "        \"\"\"\n",
        "        self.embedding_model.train()\n",
        "        device = self.embedding_model.devices[0]\n",
        "\n",
        "        loss_reconstruct = 0\n",
        "        mseLoss = nn.MSELoss()\n",
        "\n",
        "        xin0 = states[:,0].to(device) # Time-step\n",
        "\n",
        "        # Model forward for both time-steps\n",
        "        g0, xRec0 = self.embedding_model(xin0)\n",
        "        loss = (1e3)*mseLoss(xin0, xRec0)\n",
        "        loss_reconstruct = loss_reconstruct + mseLoss(xin0, xRec0).detach()\n",
        "\n",
        "        g1_old = g0\n",
        "        # Koopman transform\n",
        "        for t0 in range(1, states.shape[1]):\n",
        "            xin0 = states[:,t0,:].to(device) # Next time-step\n",
        "            _, xRec1 = self.embedding_model(xin0)\n",
        "\n",
        "            g1Pred = self.embedding_model.koopmanOperation(g1_old)\n",
        "            xgRec1 = self.embedding_model.recover(g1Pred)\n",
        "\n",
        "            loss = loss + mseLoss(xgRec1, xin0) + (1e3)*mseLoss(xRec1, xin0) \\\n",
        "                + (1e-1)*torch.sum(torch.pow(self.embedding_model.koopmanOperator, 2))\n",
        "\n",
        "            loss_reconstruct = loss_reconstruct + mseLoss(xRec1, xin0).detach()\n",
        "            g1_old = g1Pred\n",
        "\n",
        "        return loss, loss_reconstruct\n",
        "\n",
        "    def evaluate(self, states: Tensor) -> Tuple[float, Tensor, Tensor]:\n",
        "        \"\"\"Evaluates the embedding models reconstruction error and returns its\n",
        "        predictions.\n",
        "\n",
        "        Args:\n",
        "            states (Tensor): [B, T, 3] Time-series feature tensor\n",
        "\n",
        "        Returns:\n",
        "            Tuple[Float, Tensor, Tensor]: Test error, Predicted states, Target states\n",
        "        \"\"\"\n",
        "        self.embedding_model.eval()\n",
        "        device = self.embedding_model.devices[0]\n",
        "\n",
        "        mseLoss = nn.MSELoss()\n",
        "\n",
        "        # Pull out targets from prediction dataset\n",
        "        yTarget = states[:,1:].to(device)\n",
        "        xInput = states[:,:-1].to(device)\n",
        "        yPred = torch.zeros(yTarget.size()).to(device)\n",
        "\n",
        "        # Test accuracy of one time-step\n",
        "        for i in range(xInput.size(1)):\n",
        "            xInput0 = xInput[:,i].to(device)\n",
        "            g0 = self.embedding_model.embed(xInput0)\n",
        "            yPred0 = self.embedding_model.recover(g0)\n",
        "            yPred[:,i] = yPred0.squeeze().detach()\n",
        "\n",
        "        test_loss = mseLoss(yTarget, yPred)\n",
        "\n",
        "        return test_loss, yPred, yTarget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtazqCbfu8wC"
      },
      "source": [
        "## Repressilator Embedding Data-Handler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsamcNLkvFKI"
      },
      "source": [
        "class RepressilatorDataHandler(EmbeddingDataHandler):\n",
        "    \"\"\"Embedding data handler for Rossler system.\n",
        "    Contains methods for creating training and testing loaders,\n",
        "    dataset class and data collator.\n",
        "    \"\"\"\n",
        "    class RepressilatorDataset(Dataset):\n",
        "        def __init__(self, examples):\n",
        "            self.examples = examples\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.examples)\n",
        "\n",
        "        def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
        "            return {\"states\": self.examples[i]}\n",
        "\n",
        "    class RepressilatorDataCollator:\n",
        "        \"\"\"\n",
        "        Data collator for Repressilator embedding problem\n",
        "        \"\"\"\n",
        "        # Default collator\n",
        "        def __call__(self, examples:List[Dict[str, torch.Tensor]]) -> Dict[str, torch.Tensor]:\n",
        "\n",
        "            x_data_tensor =  torch.stack([example['states'] for example in examples])\n",
        "            return {\"states\": x_data_tensor}\n",
        "\n",
        "    def createTrainingLoader(\n",
        "        self,\n",
        "        file_path: str,\n",
        "        block_size: int,\n",
        "        stride:int = 1,\n",
        "        ndata:int = -1,\n",
        "        batch_size:int = 32,\n",
        "        shuffle=True,\n",
        "    ) -> DataLoader:\n",
        "        \"\"\"Creating embedding training data loader for Rossler system.\n",
        "        For a single training simulation, the total time-series is sub-chunked into\n",
        "        smaller blocks for training.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to HDF5 file with training data\n",
        "            block_size (int): The length of time-series blocks\n",
        "            stride (int): Stride of each time-series block\n",
        "            ndata (int, optional): Number of training time-series. If negative, all of the provided\n",
        "            data will be used. Defaults to -1.\n",
        "            batch_size (int, optional): Training batch size. Defaults to 32.\n",
        "            shuffle (bool, optional): Turn on mini-batch shuffling in dataloader. Defaults to True.\n",
        "\n",
        "        Returns:\n",
        "            (DataLoader): Training loader\n",
        "        \"\"\"\n",
        "        logger.info('Creating training loader')\n",
        "        assert os.path.isfile(file_path), \"Training HDF5 file {} not found\".format(file_path)\n",
        "\n",
        "        examples = []\n",
        "        with h5py.File(file_path, \"r\") as f:\n",
        "            # Iterate through stored time-series\n",
        "            samples = 0\n",
        "            for key in f.keys():\n",
        "                data_series = torch.Tensor(f[key])\n",
        "                # Stride over time-series by specified block size\n",
        "                for i in range(0,  data_series.size(0) - block_size + 1, stride):\n",
        "                    examples.append(data_series[i : i + block_size].unsqueeze(0))\n",
        "\n",
        "                samples = samples + 1\n",
        "                if(ndata > 0 and samples > ndata): #If we have enough time-series samples break loop\n",
        "                    break\n",
        "\n",
        "        data = torch.cat(examples, dim=0)\n",
        "        logger.info(\"Training data-set size: {}\".format(data.size()))\n",
        "\n",
        "        # Normalize training data\n",
        "        # Normalize x and y with Gaussian, normalize z with max/min\n",
        "        self.mu = torch.tensor([torch.mean(data[:,:,0]), torch.mean(data[:,:,1]), torch.min(data[:,:,2])])\n",
        "        self.std = torch.tensor([torch.std(data[:,:,0]), torch.std(data[:,:,1]), torch.max(data[:,:,2])-torch.min(data[:,:,2])])\n",
        "\n",
        "        # Needs to min-max normalization due to the reservoir matrix, needing to have a spectral density below 1\n",
        "        if(data.size(0) < batch_size):\n",
        "            logger.warn('Lower batch-size to {:d}'.format(data.size(0)))\n",
        "            batch_size = data.size(0)\n",
        "\n",
        "        dataset = self.RepressilatorDataset(data)\n",
        "        data_collator = self.RepressilatorDataCollator()\n",
        "        training_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=data_collator, drop_last=True)\n",
        "        return training_loader\n",
        "\n",
        "    def createTestingLoader(self,\n",
        "        file_path: str,\n",
        "        block_size: int,\n",
        "        ndata:int = -1,\n",
        "        batch_size:int=32,\n",
        "        shuffle=False\n",
        "    ) -> DataLoader:\n",
        "        \"\"\"Creating testing/validation data loader for Rossler system.\n",
        "        For a data case with time-steps [0,T], this method extract a smaller\n",
        "        time-series to be used for testing [0, S], s.t. S < T.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to HDF5 file with testing data\n",
        "            block_size (int): The length of testing time-series\n",
        "            ndata (int, optional): Number of testing time-series. If negative, all of the provided\n",
        "            data will be used. Defaults to -1.\n",
        "            batch_size (int, optional): Testing batch size. Defaults to 32.\n",
        "            shuffle (bool, optional): Turn on mini-batch shuffling in dataloader. Defaults to False.\n",
        "\n",
        "        Returns:\n",
        "            (DataLoader): Testing/validation data loader\n",
        "        \"\"\"\n",
        "        logger.info('Creating testing loader')\n",
        "        assert os.path.isfile(file_path), \"Testing HDF5 file {} not found\".format(file_path)\n",
        "\n",
        "        examples = []\n",
        "        with h5py.File(file_path, \"r\") as f:\n",
        "            # Iterate through stored time-series\n",
        "            samples = 0\n",
        "            for key in f.keys():\n",
        "                data_series = torch.Tensor(f[key])\n",
        "                # Stride over time-series\n",
        "                for i in range(0,  data_series.size(0) - block_size + 1, block_size):  # Truncate in block of block_size\n",
        "                    examples.append(data_series[i : i + block_size].unsqueeze(0))\n",
        "                    break\n",
        "\n",
        "                samples = samples + 1\n",
        "                if(ndata > 0 and samples >= ndata): #If we have enough time-series samples break loop\n",
        "                    break\n",
        "\n",
        "        # Combine data-series\n",
        "        data = torch.cat(examples, dim=0)\n",
        "        logger.info(\"Testing data-set size: {}\".format(data.size()))\n",
        "\n",
        "        if(data.size(0) < batch_size):\n",
        "            logger.warn('Lower batch-size to {:d}'.format(data.size(0)))\n",
        "            batch_size = data.size(0)\n",
        "\n",
        "        data = (data - self.mu.unsqueeze(0).unsqueeze(0)) / self.std.unsqueeze(0).unsqueeze(0)\n",
        "        dataset = self.RepressilatorDataset(data)\n",
        "        data_collator = self.RepressilatorDataCollator()\n",
        "        testing_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=data_collator, drop_last=False)\n",
        "\n",
        "        return testing_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9Fel9vqZVsH"
      },
      "source": [
        "## Initializing Datasets and Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjxiqD3lF98_"
      },
      "source": [
        "Now we can use the auto classes to initialized the predefined configs, dataloaders and models. This may take a bit!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcpC9Fy243RN",
        "outputId": "befddad6-7a07-462c-973a-00078ac75662"
      },
      "source": [
        "data_handler = RepressilatorDataHandler()\n",
        "# Set up data-loaders\n",
        "training_loader = data_handler.createTrainingLoader(\n",
        "    args.training_h5_file,\n",
        "    block_size=args.block_size,\n",
        "    stride=args.stride,\n",
        "    ndata=args.n_train,\n",
        "    batch_size=args.batch_size)\n",
        "\n",
        "testing_loader = data_handler.createTestingLoader(\n",
        "    args.eval_h5_file,\n",
        "    block_size=32,\n",
        "    ndata=args.n_eval,\n",
        "    batch_size=8)\n",
        "\n",
        "# Load configuration file then init model\n",
        "config = RepressilatorConfig()\n",
        "model = RepressilatorEmbeddingTrainer(config)\n",
        "mu, std = data_handler.norm_params\n",
        "model.embedding_model.mu = mu.to(args.device)\n",
        "model.embedding_model.std = std.to(args.device)\n",
        "\n",
        "if args.epoch_start > 1:\n",
        "    model.load_model(args.ckpt_dir, args.epoch_start)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-d3cbad9e49fa>:59: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  data_series = torch.Tensor(f[key])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of embedding parameters: 36192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auDiMVZ5UfNz"
      },
      "source": [
        "Initialize optimizer and scheduler. Feel free to change if you want to experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnrtuKdhGuWQ"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr*0.995**(args.epoch_start), weight_decay=1e-8)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.995)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It_LLGQIZe0b"
      },
      "source": [
        "## Training the Embedding Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2XPKfYTUuXf"
      },
      "source": [
        "Train the model. No visualization here, just boring numbers. This notebook only trains for 100 epochs for brevity, feel free to train longer. The test loss here is only the recovery loss MSE(x - decode(encode(x))) and does not reflect the quality of the Koopman dynamics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ic9DFQcUWpm"
      },
      "source": [
        "\n",
        "trainer = EmbeddingTrainer(model, args, (optimizer, scheduler))\n",
        "trainer.train(training_loader, testing_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3ZEE4ixh8nr"
      },
      "source": [
        "Check your Google drive for checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7J5GgEFh_8t"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}