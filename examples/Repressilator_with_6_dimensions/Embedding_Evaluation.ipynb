{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Embedding Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provide the code for evaluating the embedding model based on various criteria. The notebook must be rerun for each different embedding model, and the corresponding model architecture should be applied to each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Arguments\n",
    "This section sets up the arguments for each model. The parameters that need to be adjusted based on the embedding model used are training_h5_file, eval_h5_file, and n_embd. For the Repressilator model, the number of embeddings is set to 32 when using MLP, KAN, or MLP + KAN, and 64 when using (Encoder KAN + Decoder MLP) or (Encoder MLP + Decoder KAN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "# Torch imports\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "# Trphysx imports\n",
    "from trphysx.config import HfArgumentParser\n",
    "from trphysx.config.args import ModelArguments, TrainingArguments, DataArguments, ArgUtils\n",
    "from trphysx.embedding import EmbeddingModel\n",
    "from trphysx.config.configuration_phys import PhysConfig\n",
    "from trphysx.embedding import EmbeddingTrainingHead\n",
    "from trphysx.embedding.training import EmbeddingParser, EmbeddingDataHandler, EmbeddingTrainer\n",
    "from kan import KAN, KANLinear\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "TensorTuple = Tuple[torch.Tensor]\n",
    "FloatTuple = Tuple[float]\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "argv = []\n",
    "argv = argv + [\"--training_h5_file\", \"../../data/Repressilator/One_Parameter/Repressilator_training.hdf5\"]\n",
    "argv = argv + [\"--eval_h5_file\", \"../../data/Repressilator/One_Parameter/Repressilator_validation.hdf5\"]\n",
    "argv = argv + [\"--stride\", \"16\"]\n",
    "#argv = argv + [\"--batch_size\", \"256\"]\n",
    "argv = argv + [\"--block_size\", \"16\"]\n",
    "argv = argv + [\"--n_train\", \"10240\"]\n",
    "argv = argv + [\"--n_eval\", \"2048\"]\n",
    "argv = argv + [\"--epochs\", \"300\"]\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    filename='logging.log',\n",
    "    filemode='a',\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.DEBUG,\n",
    "    force=True,)\n",
    "\n",
    "args = EmbeddingParser().parse(argv)\n",
    "if(torch.cuda.is_available()):\n",
    "    use_cuda = \"cuda\"\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(\"Torch device: {}\".format(args.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepressilatorConfig(PhysConfig):\n",
    "    \"\"\"\n",
    "    This is the configuration class for the modeling of the Repressilator system.\n",
    "    \"\"\"\n",
    "    # same model as rossler\n",
    "    #model_type = \"rossler\"\n",
    "    model_type = \"repressilator\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_ctx=32,\n",
    "        n_embd=32,\n",
    "        n_layer=4,\n",
    "        n_head=4, # n_head must be a factor of n_embd\n",
    "        state_dims=[6],\n",
    "        activation_function=\"gelu_new\",\n",
    "        initializer_range=0.02,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "            n_ctx=n_ctx,\n",
    "            n_embd=n_embd,\n",
    "            n_layer=n_layer,\n",
    "            n_head=n_head,\n",
    "            state_dims=state_dims,\n",
    "            activation_function=activation_function,\n",
    "            initializer_range=initializer_range,\n",
    "            **kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepressilatorDataHandler(EmbeddingDataHandler):\n",
    "    \"\"\"Embedding data handler for repressilator system.\n",
    "    Contains methods for creating training and testing loaders,\n",
    "    dataset class and data collator.\n",
    "    \"\"\"\n",
    "    class RepressilatorDataset(Dataset):\n",
    "        def __init__(self, examples):\n",
    "            self.examples = examples\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.examples)\n",
    "\n",
    "        def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "            return {\"states\": self.examples[i]}\n",
    "\n",
    "    class RepressilatorDataCollator:\n",
    "        \"\"\"\n",
    "        Data collator for Repressilator embedding problem\n",
    "        \"\"\"\n",
    "        # Default collator\n",
    "        def __call__(self, examples:List[Dict[str, torch.Tensor]]) -> Dict[str, torch.Tensor]:\n",
    "\n",
    "            x_data_tensor =  torch.stack([example['states'] for example in examples])\n",
    "            return {\"states\": x_data_tensor}\n",
    "\n",
    "    def createTrainingLoader(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        block_size: int,\n",
    "        stride:int = 1,\n",
    "        ndata:int = -1,\n",
    "        batch_size:int = 32,\n",
    "        shuffle=True,\n",
    "    ) -> DataLoader:\n",
    "        \"\"\"Creating embedding training data loader for Repressilator system.\n",
    "        For a single training simulation, the total time-series is sub-chunked into\n",
    "        smaller blocks for training.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to HDF5 file with training data\n",
    "            block_size (int): The length of time-series blocks\n",
    "            stride (int): Stride of each time-series block\n",
    "            ndata (int, optional): Number of training time-series. If negative, all of the provided\n",
    "            data will be used. Defaults to -1.\n",
    "            batch_size (int, optional): Training batch size. Defaults to 32.\n",
    "            shuffle (bool, optional): Turn on mini-batch shuffling in dataloader. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            (DataLoader): Training loader\n",
    "        \"\"\"\n",
    "        logger.info('Creating training loader')\n",
    "        assert os.path.isfile(file_path), \"Training HDF5 file {} not found\".format(file_path)\n",
    "\n",
    "        examples = []\n",
    "        with h5py.File(file_path, \"r\") as f:\n",
    "            # Iterate through stored time-series\n",
    "            samples = 0\n",
    "            for key in f.keys():\n",
    "                data_series = torch.Tensor(f[key])\n",
    "                # Stride over time-series by specified block size\n",
    "                for i in range(0,  data_series.size(0) - block_size + 1, stride):\n",
    "                    examples.append(data_series[i : i + block_size].unsqueeze(0))\n",
    "\n",
    "                samples = samples + 1\n",
    "                if(ndata > 0 and samples > ndata): #If we have enough time-series samples break loop\n",
    "                    break\n",
    "\n",
    "        data = torch.cat(examples, dim=0)\n",
    "        logger.info(\"Training data-set size: {}\".format(data.size()))\n",
    "\n",
    "        # Normalize training data\n",
    "        # Normalize x and y with Gaussian, normalize z with max/min\n",
    "        self.mu = torch.tensor([torch.mean(data[:,:,0]), torch.mean(data[:,:,1]), torch.mean(data[:,:,2]),torch.mean(data[:,:,3]),torch.mean(data[:,:,4]),torch.mean(data[:,:,5])])\n",
    "        self.std = torch.tensor([torch.std(data[:,:,0]), torch.std(data[:,:,1]), torch.std(data[:,:,2]),torch.std(data[:,:,3]),torch.std(data[:,:,4]),torch.std(data[:,:,5])])\n",
    "\n",
    "        # Needs to min-max normalization due to the reservoir matrix, needing to have a spectral density below 1\n",
    "        if(data.size(0) < batch_size):\n",
    "            logger.warn('Lower batch-size to {:d}'.format(data.size(0)))\n",
    "            batch_size = data.size(0)\n",
    "\n",
    "        dataset = self.RepressilatorDataset(data)\n",
    "        data_collator = self.RepressilatorDataCollator()\n",
    "        training_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=data_collator, drop_last=True)\n",
    "        return training_loader\n",
    "\n",
    "    def createTestingLoader(self,\n",
    "        file_path: str,\n",
    "        block_size: int,\n",
    "        ndata:int = -1,\n",
    "        batch_size:int=32,\n",
    "        shuffle=False\n",
    "    ) -> DataLoader:\n",
    "        \"\"\"Creating testing/validation data loader for Repressilator system.\n",
    "        For a data case with time-steps [0,T], this method extract a smaller\n",
    "        time-series to be used for testing [0, S], s.t. S < T.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to HDF5 file with testing data\n",
    "            block_size (int): The length of testing time-series\n",
    "            ndata (int, optional): Number of testing time-series. If negative, all of the provided\n",
    "            data will be used. Defaults to -1.\n",
    "            batch_size (int, optional): Testing batch size. Defaults to 32.\n",
    "            shuffle (bool, optional): Turn on mini-batch shuffling in dataloader. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            (DataLoader): Testing/validation data loader\n",
    "        \"\"\"\n",
    "        logger.info('Creating testing loader')\n",
    "        assert os.path.isfile(file_path), \"Testing HDF5 file {} not found\".format(file_path)\n",
    "\n",
    "        examples = []\n",
    "        with h5py.File(file_path, \"r\") as f:\n",
    "            # Iterate through stored time-series\n",
    "            samples = 0\n",
    "            for key in f.keys():\n",
    "                data_series = torch.Tensor(f[key])\n",
    "                # Stride over time-series\n",
    "                x = 0\n",
    "                for i in range(0,  data_series.size(0) - block_size + 1, block_size):  # Truncate in block of block_size\n",
    "                    examples.append(data_series[i : i + block_size].unsqueeze(0))\n",
    "                    x = x + 1\n",
    "\n",
    "                samples = samples + 1\n",
    "                if(ndata > 0 and samples >= ndata): #If we have enough time-series samples break loop\n",
    "                    break\n",
    "\n",
    "        # Combine data-series\n",
    "        data = torch.cat(examples, dim=0)\n",
    "        logger.info(\"Testing data-set size: {}\".format(data.size()))\n",
    "\n",
    "        if(data.size(0) < batch_size):\n",
    "            logger.warn('Lower batch-size to {:d}'.format(data.size(0)))\n",
    "            batch_size = data.size(0)\n",
    "\n",
    "        #data = (data - self.mu.unsqueeze(0).unsqueeze(0)) / self.std.unsqueeze(0).unsqueeze(0)\n",
    "        dataset = self.RepressilatorDataset(data)\n",
    "        data_collator = self.RepressilatorDataCollator()\n",
    "        testing_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=data_collator,drop_last=False)\n",
    "\n",
    "        return testing_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5_/hq2ly88s2fxbtph44558kg8m0000gn/T/ipykernel_5223/4249061740.py:59: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "  data_series = torch.Tensor(f[key])\n"
     ]
    }
   ],
   "source": [
    "print(args.n_eval)\n",
    "\n",
    "data_handler = RepressilatorDataHandler()\n",
    "# Set up data-loaders\n",
    "\n",
    "training_loader = data_handler.createTrainingLoader(\n",
    "    args.training_h5_file,\n",
    "    block_size=args.block_size,\n",
    "    stride=args.stride,\n",
    "    ndata=args.n_train,\n",
    "    batch_size=args.batch_size)\n",
    "\n",
    "validation_loader = data_handler.createTestingLoader(\n",
    "    \"../../data/Repressilator/One_Parameter/Repressilator_validation.hdf5\",\n",
    "    block_size=1024,\n",
    "    ndata=args.n_eval,\n",
    "    batch_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Model Architecture\n",
    "\n",
    "This section of the code needs to be modified for each embedding model. Navigate to the corresponding train_repressilator_enn_{desired_architecture}.py file and copy the RepressilatorEmbedding class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Embedding Neural Network Class\"\"\"\n",
    "\n",
    "class RepressilatorEmbedding(EmbeddingModel):\n",
    "    \"\"\"Embedding model for the Repressilator ODE system\n",
    "\n",
    "    Args:\n",
    "        config (PhysConfig) Configuration class with transformer/embedding parameters\n",
    "    \"\"\"\n",
    "    #model_name = \"embedding_rossler\"\n",
    "    model_name = \"embedding_repressilator\"\n",
    "\n",
    "    def __init__(self, config: PhysConfig) -> None:\n",
    "        \"\"\"Constructor method\n",
    "        \"\"\"\n",
    "        super().__init__(config)\n",
    "\n",
    "        hidden_states = int(abs(config.state_dims[0] - config.n_embd)/2) + 1\n",
    "        hidden_states = 500\n",
    "\n",
    "        self.observableNet = nn.Sequential(\n",
    "            nn.Linear(config.state_dims[0], hidden_states),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_states, config.n_embd),\n",
    "            nn.LayerNorm(config.n_embd, eps=config.layer_norm_epsilon),\n",
    "            nn.Dropout(config.embd_pdrop)\n",
    "        )\n",
    "\n",
    "        self.recoveryNet = nn.Sequential(\n",
    "            nn.Linear(config.n_embd, hidden_states),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_states, config.state_dims[0])\n",
    "        )\n",
    "        # Learned koopman operator\n",
    "        # Learns skew-symmetric matrix with a diagonal\n",
    "        self.obsdim = config.n_embd\n",
    "        self.kMatrixDiag = nn.Parameter(torch.linspace(1, 0, config.n_embd))\n",
    "\n",
    "        xidx = []\n",
    "        yidx = []\n",
    "        for i in range(1, 3):\n",
    "            yidx.append(np.arange(i, config.n_embd))\n",
    "            xidx.append(np.arange(0, config.n_embd-i))\n",
    "\n",
    "        self.xidx = torch.LongTensor(np.concatenate(xidx))\n",
    "        self.yidx = torch.LongTensor(np.concatenate(yidx))\n",
    "        self.kMatrixUT = nn.Parameter(0.1*torch.rand(self.xidx.size(0)))\n",
    "        # Normalization occurs inside the model\n",
    "        self.register_buffer('mu', torch.tensor([0., 0., 0., 0., 0., 0.]))\n",
    "        self.register_buffer('std', torch.tensor([1., 1., 1., 1., 1., 1.]))\n",
    "        print('Number of embedding parameters: {}'.format( super().num_parameters ))\n",
    "\n",
    "    def forward(self, x: Tensor) -> TensorTuple:\n",
    "        \"\"\"Forward pass\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): [B, 6] Input feature tensor\n",
    "\n",
    "        Returns:\n",
    "            (tuple): tuple containing:\n",
    "\n",
    "                | (torch.Tensor): [B, config.n_embd] Koopman observables\n",
    "                | (torch.Tensor): [B, 6] Recovered feature tensor\n",
    "        \"\"\"\n",
    "        # Encode\n",
    "        x = self._normalize(x)\n",
    "        g = self.observableNet(x)\n",
    "        # Decode\n",
    "        out = self.recoveryNet(g)\n",
    "        xhat = self._unnormalize(out)\n",
    "        return g, xhat\n",
    "\n",
    "    def embed(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Embeds tensor of state variables to Koopman observables\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): [B, 6] input feature tensor\n",
    "\n",
    "        Returns:\n",
    "            (Tensor): [B, config.n_embd] Koopman observables\n",
    "        \"\"\"\n",
    "        x = self._normalize(x)\n",
    "        g = self.observableNet(x)\n",
    "        return g\n",
    "\n",
    "    def recover(self, g: Tensor) -> Tensor:\n",
    "        \"\"\"Recovers feature tensor from Koopman observables\n",
    "\n",
    "        Args:\n",
    "            g (Tensor): [B, config.n_embd] Koopman observables\n",
    "\n",
    "        Returns:\n",
    "            (Tensor): [B, 6] Physical feature tensor\n",
    "        \"\"\"\n",
    "        out = self.recoveryNet(g)\n",
    "        x = self._unnormalize(out)\n",
    "        return x\n",
    "\n",
    "    def koopmanOperation(self, g: Tensor) -> Tensor:\n",
    "        \"\"\"Applies the learned koopman operator on the given observables.\n",
    "\n",
    "        Args:\n",
    "            (Tensor): [B, config.n_embd] Koopman observables\n",
    "\n",
    "        Returns:\n",
    "            (Tensor): [B, config.n_embd] Koopman observables at the next time-step\n",
    "        \"\"\"\n",
    "        # Koopman operator\n",
    "        kMatrix = Variable(torch.zeros(self.obsdim, self.obsdim)).to(self.kMatrixUT.device)\n",
    "        # Populate the off diagonal terms\n",
    "        kMatrix[self.xidx, self.yidx] = self.kMatrixUT\n",
    "        kMatrix[self.yidx, self.xidx] = -self.kMatrixUT\n",
    "\n",
    "        # Populate the diagonal\n",
    "        ind = np.diag_indices(kMatrix.shape[0])\n",
    "        kMatrix[ind[0], ind[1]] = self.kMatrixDiag\n",
    "\n",
    "        # Apply Koopman operation\n",
    "        gnext = torch.bmm(kMatrix.expand(g.size(0), kMatrix.size(0), kMatrix.size(0)), g.unsqueeze(-1))\n",
    "        self.kMatrix = kMatrix\n",
    "        return gnext.squeeze(-1) # Squeeze empty dim from bmm\n",
    "\n",
    "    @property\n",
    "    def koopmanOperator(self, requires_grad: bool = True) -> Tensor:\n",
    "        \"\"\"Current Koopman operator\n",
    "\n",
    "        Args:\n",
    "            requires_grad (bool, optional): if to return with gradient storage, defaults to True\n",
    "        \"\"\"\n",
    "        if not requires_grad:\n",
    "            return self.kMatrix.detach()\n",
    "        else:\n",
    "            return self.kMatrix\n",
    "\n",
    "    def _normalize(self, x: Tensor) -> Tensor:\n",
    "        return (x - self.mu.unsqueeze(0))/self.std.unsqueeze(0)\n",
    "\n",
    "    def _unnormalize(self, x: Tensor) -> Tensor:\n",
    "        return self.std.unsqueeze(0)*x + self.mu.unsqueeze(0)\n",
    "\n",
    "    @property\n",
    "    def koopmanDiag(self):\n",
    "        return self.kMatrixDiag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument Utility and Loading the model\n",
    "this part you just need to run it without modeification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arg Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=====\n",
    "Distributed by: Notre Dame SCAI Lab (MIT Liscense)\n",
    "- Associated publication:\n",
    "url: https://arxiv.org/abs/2010.03957\n",
    "doi:\n",
    "github: https://github.com/zabaras/transformer-physx\n",
    "=====\n",
    "\"\"\"\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Tuple #Needs python 3.8 for literal\n",
    "\n",
    "HOME = os.getcwd()\n",
    "INITS = ['lorenz', 'cylinder', 'grayscott']\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.\n",
    "    \"\"\"\n",
    "    init_name: str = field(\n",
    "        default='lorenz', metadata={\"help\": \"Used as a global default initialization token for different experiments.\"}\n",
    "    )\n",
    "    model_name: str = field(\n",
    "        default=None, metadata={\"help\": \"The name model of the transformer model\"},\n",
    "    )\n",
    "    config_name: str = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    embedding_name: str = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained embedding model name\"}\n",
    "    )\n",
    "    embedding_file_or_path: str = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained embedding model path\"}\n",
    "    )\n",
    "    transformer_file_or_path: str = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained transformer model path\"}\n",
    "    )\n",
    "    viz_name: str = field(\n",
    "        default=None, metadata={\"help\": \"Visualization class name\"}\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class DataArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to training and evaluation data.\n",
    "    \"\"\"\n",
    "    n_train: int = field(\n",
    "        default=2048, metadata={\"help\": \"Number of training time-series to use\"}\n",
    "    )\n",
    "    n_eval: int = field(\n",
    "        default=256, metadata={\"help\": \"Number of evaluation time-series to use\"}\n",
    "    )\n",
    "    stride: int = field(\n",
    "        default=32, metadata={\"help\": \" Stride to segment the training data at\"}\n",
    "    )\n",
    "    training_h5_file: str = field(\n",
    "        default=None, metadata={\"help\": \"File path to the training data hdf5 file\"}\n",
    "    )\n",
    "    eval_h5_file: str = field(\n",
    "        default=None, metadata={\"help\": \"File path to the evaluation data hdf5 file\"}\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets\"}\n",
    "    )\n",
    "    cache_path:str= field(\n",
    "        default=None, metadata={\"help\": \"File directory to write cache file to\"}\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class TrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "    \"\"\"\n",
    "    block_size: int = field(\n",
    "        default=-1,\n",
    "        metadata={\n",
    "            \"help\": \"Optional input sequence length after tokenization.\"\n",
    "            \"The training dataset will be truncated in block of this size for training.\"\n",
    "            \"Default to the model max input length for single sentence inputs (take into account special tokens).\"\n",
    "        },\n",
    "    )\n",
    "    # Training paths for logging, checkpoints etc.\n",
    "    exp_dir: str = field(\n",
    "        default=None, metadata={\"help\": \"Directory to store data related to the experiment\"}\n",
    "    )\n",
    "    ckpt_dir: str = field(\n",
    "        default=None, metadata={\"help\": \"Directory to save model checkpoints during training\"}\n",
    "    )\n",
    "    plot_dir: str = field(\n",
    "        default=None, metadata={\"help\": \"Directory to save plots during training\"}\n",
    "    )\n",
    "    save_steps: int = field(\n",
    "        default=25, metadata={\"help\": \"Epoch stride to save checkpoints\"}\n",
    "    )\n",
    "    eval_steps: int = field(\n",
    "        default=25, metadata={\"help\": \"Epoch stride to evaluate validation data-set\"}\n",
    "    )\n",
    "    plot_max: int = field(\n",
    "        default=3, metadata={\"help\": \"Max number of eval cases to plot\"}\n",
    "    )\n",
    "\n",
    "    epoch_start: int = field(\n",
    "        default=0, metadata={\"help\": \"Epoch to start training at\"}\n",
    "    )\n",
    "    epochs: int = field(\n",
    "        default=200, metadata={\"help\": \"Number of epochs to train\"}\n",
    "    )\n",
    "\n",
    "    # ===== Optimization parameters =====\n",
    "    lr: float = field(\n",
    "        default=0.001, metadata={\"help\": \"Learning rate\"}\n",
    "    )\n",
    "    max_grad_norm: float = field(\n",
    "        default=0.1, metadata={\"help\": \"Norm limit for clipping gradients\"}\n",
    "    )\n",
    "    dataloader_drop_last: bool = field(\n",
    "        default=True, metadata={\"help\": \"Drop training cases no in a full mini-batch\"}\n",
    "    )\n",
    "    gradient_accumulation_steps: int = field(\n",
    "        default=int(1), metadata={\"help\": \"How many mini-batches to compute before updating weights\"}\n",
    "    )\n",
    "\n",
    "    # ===== Data loader parameters =====\n",
    "    train_batch_size: int = field(\n",
    "        default=256, metadata={\"help\": \"Number of training cases in mini-batch\"}\n",
    "    )\n",
    "    eval_batch_size: int = field(\n",
    "        default=16, metadata={\"help\": \"Number of evaluation cases in mini-batch\"}\n",
    "    )\n",
    "\n",
    "    # ===== Parallel parameters =====\n",
    "    local_rank: int = field(\n",
    "        default=-1, metadata={\"help\": \"Local rank of the CPU process, -1 means just use a single CPU\"}\n",
    "    )\n",
    "    n_gpu: int = field(\n",
    "        default=1, metadata={\"help\": \"Number of GPUs per CPU\"}\n",
    "    )\n",
    "    seed: int = field(\n",
    "        default=12345, metadata={\"help\": \"Random seed for reproducibility\"}\n",
    "    )\n",
    "    notes: str = field(\n",
    "        default=None, metadata={\"help\": \"Notes that will be appended to experiment folder\"}\n",
    "    )\n",
    "\n",
    "\n",
    "class ArgUtils:\n",
    "    \"\"\"Argument utility class for modifying particular arguments after initialization\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def config(\n",
    "        cls,\n",
    "        modelArgs: ModelArguments,\n",
    "        dataArgs: DataArguments,\n",
    "        trainingArgs: TrainingArguments,\n",
    "        create_paths: bool = True\n",
    "    ) -> Tuple[ModelArguments, DataArguments, TrainingArguments]:\n",
    "        \"\"\"Runs additional runtime configuration updates for argument instances\n",
    "\n",
    "        Args:\n",
    "            modelArgs (ModelArguments): Transformer model arguments\n",
    "            dataArgs (DataArguments): Data loader/ data set arguments\n",
    "            trainingArgs (TrainingArguments): Training arguments\n",
    "            create_paths (bool, optional): Create training/testing folders. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[ModelArguments, DataArguments, TrainingArguments]: Updated argument instances\n",
    "        \"\"\"\n",
    "        modelArgs = cls.configModelNames(modelArgs)\n",
    "\n",
    "        if create_paths:\n",
    "            modelArgs, dataArgs, trainingArgs = cls.configPaths(modelArgs, dataArgs, trainingArgs)\n",
    "\n",
    "        trainingArgs = cls.configTorchDevices(trainingArgs)\n",
    "\n",
    "        return modelArgs, dataArgs, trainingArgs\n",
    "\n",
    "    @classmethod\n",
    "    def configModelNames(cls, modelArgs: ModelArguments) -> ModelArguments:\n",
    "        # Set up model, config, viz and embedding names\n",
    "        if not modelArgs.init_name in INITS:\n",
    "            logger.warn('Selected init name not in built-in models. Be careful.')\n",
    "\n",
    "        attribs = [\"model_name\", \"config_name\", \"embedding_name\", \"viz_name\"]\n",
    "        for attrib in attribs:\n",
    "            if getattr(modelArgs, attrib) is None:\n",
    "                setattr(modelArgs, attrib, modelArgs.init_name)\n",
    "\n",
    "        return modelArgs\n",
    "\n",
    "    @classmethod\n",
    "    def configPaths(\n",
    "        cls,\n",
    "        modelArgs: ModelArguments,\n",
    "        dataArgs: DataArguments,\n",
    "        trainingArgs: TrainingArguments\n",
    "    ) -> Tuple[ModelArguments, DataArguments, TrainingArguments]:\n",
    "        \"\"\"Sets up various folder path parameters\n",
    "\n",
    "        Args:\n",
    "            modelArgs (ModelArguments): Transformer model arguments\n",
    "            dataArgs (DataArguments): Data loader/ data set arguments\n",
    "            trainingArgs (TrainingArguments): Training arguments\n",
    "\n",
    "        Returns:\n",
    "            Tuple[ModelArguments, DataArguments, TrainingArguments]: Updated argument instances\n",
    "        \"\"\"\n",
    "        if(trainingArgs.exp_dir is None):\n",
    "            trainingArgs.exp_dir = os.path.join(HOME, 'outputs', 'transformer_{:s}'.format(modelArgs.config_name), \\\n",
    "                    'ntrain{:d}_epochs{:d}_batch{:d}'.format(dataArgs.n_train, trainingArgs.epochs, trainingArgs.train_batch_size))\n",
    "            if trainingArgs.notes: # If notes add them to experiment folder name\n",
    "                trainingArgs.exp_dir = os.path.join(os.path.dirname(trainingArgs.exp_dir), os.path.basename(trainingArgs.exp_dir)+'_{:s}'.format(trainingArgs.notes))\n",
    "\n",
    "        if(trainingArgs.ckpt_dir is None):\n",
    "            trainingArgs.ckpt_dir = os.path.join(trainingArgs.exp_dir, 'checkpoints')\n",
    "\n",
    "        if(trainingArgs.plot_dir is None):\n",
    "            trainingArgs.plot_dir = os.path.join(trainingArgs.exp_dir, 'viz')\n",
    "\n",
    "        # Create directories if they don't exist already\n",
    "        os.makedirs(trainingArgs.exp_dir, exist_ok=True)\n",
    "        os.makedirs(trainingArgs.ckpt_dir, exist_ok=True)\n",
    "        os.makedirs(trainingArgs.plot_dir, exist_ok=True)\n",
    "\n",
    "        return modelArgs, dataArgs, trainingArgs\n",
    "\n",
    "    @classmethod\n",
    "    def configTorchDevices(cls, args: TrainingArguments) -> TrainingArguments:\n",
    "        \"\"\"Sets up device ids for training\n",
    "\n",
    "        Args:\n",
    "            args (TrainingArguments): Training arguments\n",
    "\n",
    "        Returns:\n",
    "            TrainingArguments: Updated argument instance\n",
    "        \"\"\"\n",
    "        # Set up parallel PyTorch device(s)\n",
    "        if(torch.cuda.device_count() > 1 and args.n_gpu > 1):\n",
    "            if(torch.cuda.device_count() < args.n_gpu):\n",
    "                args.n_gpu = torch.cuda.device_count()\n",
    "            if(args.n_gpu < 1):\n",
    "                args.n_gpu = torch.cuda.device_count()\n",
    "            logging.info(\"Looks like we have {:d} GPUs to use. Going parallel.\".format(args.n_gpu))\n",
    "            args.device_ids = [i for i in range(0,args.n_gpu)]\n",
    "            args.src_device = \"cuda:{}\".format(args.device_ids[0])\n",
    "        # Set up parallel PyTorch single GPU device\n",
    "        elif(torch.cuda.is_available()):\n",
    "            logging.info(\"Using a single GPU for training.\")\n",
    "            args.device_ids = [0]\n",
    "            args.src_device = \"cuda:{}\".format(args.device_ids[0])\n",
    "            args.n_gpu = 1\n",
    "        # CPU only\n",
    "        else:\n",
    "            logging.info(\"No GPUs found, will be training on CPU.\")\n",
    "            args.src_device = \"cpu\"\n",
    "\n",
    "        return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embedding parameters: 39195\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parse arguments using the hugging face argument parser\n",
    "parser = HfArgumentParser((ModelArguments, DataArguments, TrainingArguments))\n",
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses(argv)\n",
    "\n",
    "model_args, data_args, training_args = ArgUtils.config(model_args, data_args, training_args)\n",
    "# Rossler configuration\n",
    "config = RepressilatorConfig()\n",
    "# Load embedding model\n",
    "embedding_model = RepressilatorEmbedding(config).to(training_args.src_device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Prediction and Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_reconstruction(eval_dataloader: DataLoader, embedding_model: EmbeddingModel):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for states in eval_dataloader:\n",
    "\n",
    "            states = states['states']\n",
    "                \n",
    "            embedding_model.eval()\n",
    "            device = embedding_model.devices[0]\n",
    "\n",
    "            mseLoss = nn.MSELoss()\n",
    "\n",
    "            yTarget = states[:,:].to(device)\n",
    "            xInput = states[:,:].to(device)\n",
    "            yPred = torch.zeros(yTarget.size()).to(device) \n",
    "            # Test accuracy of one time-step\n",
    "            for i in range(xInput.size(1)):\n",
    "                xInput0 = xInput[:,i].to(device)\n",
    "                g0 = embedding_model.embed(xInput0)\n",
    "                yPred0 = embedding_model.recover(g0).detach()\n",
    "                yPred[:,i] = yPred0.squeeze()\n",
    "            \n",
    "            loss = mseLoss(yTarget, yPred)/len(eval_dataloader)\n",
    "            test_loss = test_loss + loss\n",
    "            test_loss = test_loss \n",
    "    return test_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the next prediction of the model\n",
    "def evaluate_next_prediction(eval_dataloader: DataLoader, embedding_model: EmbeddingModel):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for states in eval_dataloader:\n",
    "\n",
    "            states = states['states']\n",
    "            \n",
    "                \n",
    "            embedding_model.eval()\n",
    "            device = embedding_model.devices[0]\n",
    "\n",
    "            mseLoss = nn.MSELoss()\n",
    "\n",
    "            yTarget = states[:,1:].to(device)\n",
    "            xInput = states[:,:-1].to(device)\n",
    "            yPred = torch.zeros(yTarget.size()).to(device) \n",
    "            # Test accuracy of one time-step\n",
    "            for i in range(xInput.size(1)):\n",
    "                xInput0 = xInput[:,i].to(device)\n",
    "                g0 = embedding_model.embed(xInput0)\n",
    "                g1 = embedding_model.koopmanOperation(g0)\n",
    "                yPred0 = embedding_model.recover(g1).detach()\n",
    "                yPred[:,i] = yPred0.squeeze()\n",
    "            \n",
    "            loss = mseLoss(yTarget, yPred) / len(eval_dataloader)\n",
    "            test_loss = test_loss + loss\n",
    "            test_loss = test_loss \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Write down the path for the checkpoints for the embedding model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Reconstruction loss: 0.0274432618\n",
      "Test Prediction loss: 0.4777341187\n",
      "Test Reconstruction loss: 0.0314728431\n",
      "Test Prediction loss: 0.4231641293\n",
      "Test Reconstruction loss: 0.0290263481\n",
      "Test Prediction loss: 0.1733724177\n",
      "Test Reconstruction loss: 0.0157393701\n",
      "Test Prediction loss: 0.1774320900\n",
      "Test Reconstruction loss: 0.0110473009\n",
      "Test Prediction loss: 0.1319861710\n",
      "Test Reconstruction loss: 0.0158657823\n",
      "Test Prediction loss: 0.1147892997\n",
      "Test Reconstruction loss: 0.0057862415\n",
      "Test Prediction loss: 0.0943471491\n",
      "Test Reconstruction loss: 0.0049849944\n",
      "Test Prediction loss: 0.0891392678\n",
      "Test Reconstruction loss: 0.0039107669\n",
      "Test Prediction loss: 0.0852381065\n",
      "Test Reconstruction loss: 0.0053483546\n",
      "Test Prediction loss: 0.0817463323\n",
      "Test Reconstruction loss: 0.0023220070\n",
      "Test Prediction loss: 0.0760205612\n",
      "Test Reconstruction loss: 0.0018877045\n",
      "Test Prediction loss: 0.0694253147\n"
     ]
    }
   ],
   "source": [
    "embedding_path_m = \"/Users/mohammedahmed/Desktop/Project/PROJECT/transformer-physx-main/examples/Repressilator_with_6_dimensions/mlp/outputs/embedding_mlp/ntrain10240_epochs300_batch256/checkpoints\"\n",
    "mds = [25,50,75,100,125,150,175,200,225,250,275,300]\n",
    "# use the embedding path and change the embedding model using mds and save the test loss of each model in a list\n",
    "test_reconstruction_loss_list = []\n",
    "test_pred_loss_list = []\n",
    "\n",
    "for md in mds:\n",
    "    embedding_model.load_model(os.path.join(embedding_path_m, f'embedding_repressilator{md}.pth'))\n",
    "    test_r_loss = evaluate_reconstruction(validation_loader, embedding_model)\n",
    "    test_pred_loss = evaluate_next_prediction(validation_loader, embedding_model)\n",
    "    test_reconstruction_loss_list.append(test_r_loss)\n",
    "    test_pred_loss_list.append(test_pred_loss)\n",
    "    print('Test Reconstruction loss: {:.10f}'.format(test_r_loss))\n",
    "    print('Test Prediction loss: {:.10f}'.format(test_pred_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction loss list mlp: [0.02744326 0.03147284 0.02902635 0.01573937 0.0110473  0.01586578\n",
      " 0.00578624 0.00498499 0.00391077 0.00534835 0.00232201 0.0018877 ]\n",
      "prediction loss list mlp: [0.47773412 0.42316413 0.17337242 0.17743209 0.13198617 0.1147893\n",
      " 0.09434715 0.08913927 0.08523811 0.08174633 0.07602056 0.06942531]\n"
     ]
    }
   ],
   "source": [
    "# move both losses to cpu and convert them to numpy arrays\n",
    "test_reconstruction_loss_list = torch.tensor(test_reconstruction_loss_list).cpu().numpy()\n",
    "test_pred_loss_list = torch.tensor(test_pred_loss_list).cpu().numpy()\n",
    "\n",
    "print(f'reconstruction loss list mlp: {test_reconstruction_loss_list}')\n",
    "print(f'prediction loss list mlp: {test_pred_loss_list}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Isotropic Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedahmed/miniconda3/envs/physx/lib/python3.8/site-packages/trphysx/embedding/embedding_model.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(file_or_path_directory, map_location=lambda storage, loc: storage))\n"
     ]
    }
   ],
   "source": [
    "embedding_model.load_model(os.path.join(\"./mlp/outputs/embedding_mlp/ntrain10240_epochs300_batch256/checkpoints\", f'embedding_repressilator300.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the Original data and the embedded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embedding_model.eval()\n",
    "device = embedding_model.devices[0]\n",
    "with torch.no_grad():\n",
    "    embedding = []\n",
    "    true_data = []\n",
    "    for states in validation_loader:\n",
    "        states = states['states']\n",
    "        for i in range(states.size(1)):\n",
    "            xInput0 = states[:,i].to(device)\n",
    "            g0 = embedding_model.embed(xInput0)\n",
    "            g0 = g0.permute(1,0)\n",
    "            embedding.append(g0)\n",
    "            true_data.append(states[:,i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65536, 32)\n",
      "(65536, 6)\n"
     ]
    }
   ],
   "source": [
    "# transform embedding into numpy array\n",
    "embedding = torch.cat(embedding, dim=1).cpu().numpy()\n",
    "embedding = embedding.T\n",
    "print(embedding.shape)\n",
    "true_data = torch.cat(true_data, dim=0).cpu().numpy()\n",
    "print(true_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def average_cosine_similarity(data, num_samples=10000):\n",
    "  \"\"\"Calculates the average cosine similarity for a given number of random points.\n",
    "\n",
    "  Args:\n",
    "    data: A numpy array of shape (p, d) where p is the number of points and d is the dimension.\n",
    "    num_samples: The number of random points to sample.\n",
    "\n",
    "  Returns:\n",
    "    The average cosine similarity between the sampled points.\n",
    "  \"\"\"\n",
    "\n",
    "  p, d = data.shape\n",
    "  if num_samples > p:\n",
    "    raise ValueError(\"Number of samples cannot be greater than the number of points\")\n",
    "\n",
    "  # Sample random indices without replacement\n",
    "  random_indices = np.random.choice(p, size=num_samples, replace=False)\n",
    "\n",
    "  # Extract the corresponding points\n",
    "  sampled_data = data[random_indices]\n",
    "\n",
    "  # Calculate pairwise cosine similarities\n",
    "  similarities = cosine_similarity(sampled_data)\n",
    "\n",
    "  # Exclude self-similarities (diagonal elements)\n",
    "  similarities = similarities[np.triu_indices_from(similarities, k=1)]\n",
    "\n",
    "  # Calculate the average cosine similarity\n",
    "  average_similarity = np.mean(similarities)\n",
    "\n",
    "  return average_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity score: 0.8895577788352966\n"
     ]
    }
   ],
   "source": [
    "print(f'Average cosine similarity score: {average_cosine_similarity(embedding)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity score: 0.6333780288696289\n"
     ]
    }
   ],
   "source": [
    "print(f'Average cosine similarity score: {average_cosine_similarity(true_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for the embedding of the MLP, KAN and MLP +KAN I used the function below for calculating the exact partition score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_score(points):\n",
    "    \"\"\"Partition score of isotropy taken from Mu et al. 2018.  \n",
    "       1 is isotropic and 0 in anisotropic.\"\"\"\n",
    "    _, C = np.linalg.eig(np.matmul(points,points.T))\n",
    "    scores = []\n",
    "    for c in C:\n",
    "        scores.append(np.sum(np.exp(c*points.T)))\n",
    "    return min(scores)/max(scores) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given the substantial size of the embedding space, we opted to approximate rather than compute exact values for the (KAN encoder and MLP decoder) and (MLP encoder and MLP decoder) architectures. The use of exact calculations resulted in kernel crashes.For this reason, we employed the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def partition_score(data, num_eigenvalues=100):\n",
    "  \"\"\"Calculates an approximation of the partition score.\n",
    "\n",
    "  Args:\n",
    "    data: A numpy array of shape (num_points, dimensions).\n",
    "    num_eigenvalues: The number of eigenvalues to consider for approximation.\n",
    "\n",
    "  Returns:\n",
    "    An approximation of the partition score.\n",
    "  \"\"\"\n",
    "  data = np.array(data)- np.mean(data)\n",
    "  # Calculate covariance matrix\n",
    "  cov_matrix = np.cov(data.T)\n",
    "\n",
    "  # Calculate eigenvalues and eigenvectors\n",
    "  eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "  scores = []\n",
    "  \n",
    "  for i in range(len(eigenvalues)):\n",
    "    score = np.sum(np.exp(eigenvalues[i] * data))\n",
    "    scores.append(score)\n",
    "  arranged_scores = np.sort(scores)\n",
    "  return min(scores)/max(scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(f'partition score: {partition_score(embedding)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The VarEx Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def varex_score(points, p=0.3):\n",
    "  \"\"\"Computes how uniformly the first p% of principal components of points are distributed.\n",
    "\n",
    "  Args:\n",
    "    points: A numpy array of shape (number of points, dimension) representing the points.\n",
    "    p: The percentage of principal components to consider.\n",
    "\n",
    "  Returns:\n",
    "    The varex score, a measure of uniformity in variance distribution.\n",
    "  \"\"\"\n",
    "\n",
    "  _, n = points.shape\n",
    "  print(points.shape)\n",
    "  #num_components = int(np.floor(n * p))\n",
    "  num_components = 3\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  data_standardized = scaler.fit_transform(points)\n",
    "  pca_model = PCA(n_components=num_components)\n",
    "  pc_embed = pca_model.fit_transform(data_standardized)\n",
    "\n",
    "  # Explained variance for each principal component\n",
    "  explained_variance_ratio = pca_model.explained_variance_ratio_\n",
    "\n",
    "  # Varex score (total variance explained)\n",
    "  varex_score = np.sum(explained_variance_ratio)\n",
    "\n",
    "  print(f\"Explained Variance Ratio: {explained_variance_ratio}\")\n",
    "  print(f\"Varex Score (Variance Explained): {varex_score}\")\n",
    "\n",
    "  return varex_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65536, 32)\n",
      "Explained Variance Ratio: [0.34522158 0.29615283 0.15111923]\n",
      "Varex Score (Variance Explained): 0.7924936413764954\n",
      "varex score: 0.7924936413764954\n"
     ]
    }
   ],
   "source": [
    "print(f'varex score: {varex_score(embedding, p=0.2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IsoScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IsoScore import IsoScore\n",
    "# transform the embedding to cpu\n",
    "embedding = embedding\n",
    "score = IsoScore.IsoScore(embedding)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohammedahmed/miniconda3/envs/physx/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Example data:\n",
    "# original_data: 6-dimensional data\n",
    "np.random.seed(42)\n",
    "labels = np.random.randint(0, 5, 65536)   # 5 classes for coloring\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "# For original 6D space\n",
    "umap_original = umap.UMAP(n_neighbors=64, min_dist=0.1, n_components=2)\n",
    "original_data_2d = umap_original.fit_transform(true_data)\n",
    "\n",
    "# For embedded 32D space\n",
    "umap_embedded = umap.UMAP(n_neighbors=64, min_dist=0.05, n_components=2)\n",
    "embedded_data_2d = umap_embedded.fit_transform(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the original and embedded data in 2d\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot original data\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(original_data_2d[:, 0], original_data_2d[:, 1], c=labels, cmap='Spectral', s=5)\n",
    "plt.title('UMAP Projection of Original 6D Data')\n",
    "\n",
    "# Plot embedded data\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(embedded_data_2d[:, 0], embedded_data_2d[:, 1], c=labels, cmap='Spectral', s=5)\n",
    "plt.title('UMAP Projection of Embedded 64D Data')\n",
    "\n",
    "plt.savefig('original_embedded_data_eKdM.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard and Hit Rate Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Neighbors: [[    0 43009     1 ... 57345 43011 57346]\n",
      " [    1 43010     2 ... 43012 43008 57345]\n",
      " [    2     3 43011 ... 43013 43009     5]\n",
      " ...\n",
      " [65533 21270 28430 ...  7971 43894 39912]\n",
      " [65534 21271 28431 ... 16356  7972 39913]\n",
      " [65535 21272 28432 ... 16357 18328 39914]]\n",
      "Embedded Data Neighbors: [[    0 43009 43008 ... 57344 57345     3]\n",
      " [    1 43010     2 ... 43008 43012 57345]\n",
      " [    2 43011     3 ... 43013 43009     0]\n",
      " ...\n",
      " [65533 21270 28430 ... 60210 20379 54177]\n",
      " [65534 21271 28431 ... 60211 54178 20380]\n",
      " [65535 21272 28432 ... 60212 54179 18328]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# Number of neighbors to consider\n",
    "n_neighbors = 10  # or any number appropriate for your analysis\n",
    "\n",
    "# Calculate neighbors for original data\n",
    "nbrs_original = NearestNeighbors(n_neighbors=n_neighbors).fit(true_data)\n",
    "distances_original, indices_original = nbrs_original.kneighbors(true_data)\n",
    "\n",
    "# Calculate neighbors for each embedding\n",
    "nbrs_embedded_1 = NearestNeighbors(n_neighbors=n_neighbors).fit(embedding)\n",
    "distances_embedded_1, indices_embedded_1 = nbrs_embedded_1.kneighbors(embedding)\n",
    "\n",
    "\n",
    "print(f'Original Data Neighbors: {indices_original}')\n",
    "print(f'Embedded Data Neighbors: {indices_embedded_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(list1, list2):\n",
    "    intersection = len(set(list1).intersection(list2))\n",
    "    union = len(set(list1).union(list2))\n",
    "    return intersection / union\n",
    "\n",
    "jaccard_scores_1 = []\n",
    "for i in range(len(true_data)):\n",
    "    jaccard = jaccard_index(indices_original[i], indices_embedded_1[i])\n",
    "    jaccard_scores_1.append(jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Jaccard Index for Embedding 1: 0.7553834268991722\n"
     ]
    }
   ],
   "source": [
    "mean_jaccard_1 = np.mean(jaccard_scores_1)\n",
    "print(f\"Mean Jaccard Index for Embedding 1: {mean_jaccard_1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate for Embedding 1: 0.8509124755859375\n"
     ]
    }
   ],
   "source": [
    "def hit_rate(original_indices, embedded_indices):\n",
    "    hits = 0\n",
    "    for i in range(len(original_indices)):\n",
    "        hits += len(set(original_indices[i]).intersection(embedded_indices[i]))\n",
    "    return hits / (len(original_indices) * len(original_indices[0]))\n",
    "\n",
    "hit_rate_1 = hit_rate(indices_original, indices_embedded_1)\n",
    "\n",
    "print(f\"Hit Rate for Embedding 1: {hit_rate_1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
